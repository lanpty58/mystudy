{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rjQLIg_W96_LgYLZNRCgw3KxqyMsjeyJ",
      "authorship_tag": "ABX9TyNERGjcxu6PdX574qZuXvZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lanpty58/mystudy/blob/main/Video_Enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFqbBZxbh4Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oG2Qslnt7xZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b5a88e-2d2e-4399-bfed-7f35fbab9aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mamba-ssm in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (1.11.1.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install causal-conv1d>=1.2.0\n",
        "!pip install mamba-ssm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "FbPgkLiLiAIL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "KazSkmeE3fmr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model = resnet18(pretrained=True).cuda()\n",
        "# model = torch.nn.Sequential(*(list(model.children())[:-2]))\n",
        "# print(model)\n",
        "summary(model, (3, 512, 512))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJsU0btKF6NQ",
        "outputId": "de7cc42b-8cb5-4be3-ea01-14a26a506a24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
            "              ReLU-3         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
            "            Conv2d-5         [-1, 64, 128, 128]          36,864\n",
            "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
            "              ReLU-7         [-1, 64, 128, 128]               0\n",
            "            Conv2d-8         [-1, 64, 128, 128]          36,864\n",
            "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
            "             ReLU-10         [-1, 64, 128, 128]               0\n",
            "       BasicBlock-11         [-1, 64, 128, 128]               0\n",
            "           Conv2d-12         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-13         [-1, 64, 128, 128]             128\n",
            "             ReLU-14         [-1, 64, 128, 128]               0\n",
            "           Conv2d-15         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-16         [-1, 64, 128, 128]             128\n",
            "             ReLU-17         [-1, 64, 128, 128]               0\n",
            "       BasicBlock-18         [-1, 64, 128, 128]               0\n",
            "           Conv2d-19          [-1, 128, 64, 64]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 64, 64]             256\n",
            "             ReLU-21          [-1, 128, 64, 64]               0\n",
            "           Conv2d-22          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 64, 64]             256\n",
            "           Conv2d-24          [-1, 128, 64, 64]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 64, 64]             256\n",
            "             ReLU-26          [-1, 128, 64, 64]               0\n",
            "       BasicBlock-27          [-1, 128, 64, 64]               0\n",
            "           Conv2d-28          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 64, 64]             256\n",
            "             ReLU-30          [-1, 128, 64, 64]               0\n",
            "           Conv2d-31          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 64, 64]             256\n",
            "             ReLU-33          [-1, 128, 64, 64]               0\n",
            "       BasicBlock-34          [-1, 128, 64, 64]               0\n",
            "           Conv2d-35          [-1, 256, 32, 32]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 32, 32]             512\n",
            "             ReLU-37          [-1, 256, 32, 32]               0\n",
            "           Conv2d-38          [-1, 256, 32, 32]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 32, 32]             512\n",
            "           Conv2d-40          [-1, 256, 32, 32]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 32, 32]             512\n",
            "             ReLU-42          [-1, 256, 32, 32]               0\n",
            "       BasicBlock-43          [-1, 256, 32, 32]               0\n",
            "           Conv2d-44          [-1, 256, 32, 32]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 32, 32]             512\n",
            "             ReLU-46          [-1, 256, 32, 32]               0\n",
            "           Conv2d-47          [-1, 256, 32, 32]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 32, 32]             512\n",
            "             ReLU-49          [-1, 256, 32, 32]               0\n",
            "       BasicBlock-50          [-1, 256, 32, 32]               0\n",
            "           Conv2d-51          [-1, 512, 16, 16]       1,179,648\n",
            "      BatchNorm2d-52          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-53          [-1, 512, 16, 16]               0\n",
            "           Conv2d-54          [-1, 512, 16, 16]       2,359,296\n",
            "      BatchNorm2d-55          [-1, 512, 16, 16]           1,024\n",
            "           Conv2d-56          [-1, 512, 16, 16]         131,072\n",
            "      BatchNorm2d-57          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-58          [-1, 512, 16, 16]               0\n",
            "       BasicBlock-59          [-1, 512, 16, 16]               0\n",
            "           Conv2d-60          [-1, 512, 16, 16]       2,359,296\n",
            "      BatchNorm2d-61          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-62          [-1, 512, 16, 16]               0\n",
            "           Conv2d-63          [-1, 512, 16, 16]       2,359,296\n",
            "      BatchNorm2d-64          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-65          [-1, 512, 16, 16]               0\n",
            "       BasicBlock-66          [-1, 512, 16, 16]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.00\n",
            "Forward/backward pass size (MB): 328.01\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 375.60\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown 1N93rb_uFqKRZ9naX8CXShFt5RJHOmjZH"
      ],
      "metadata": {
        "id": "kh1GFGquNmXR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AI/data/rwf-2000.zip"
      ],
      "metadata": {
        "id": "VPvPMyB2VF2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a6c436-910d-49f0-d0c6-5a4709b14060"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/AI/data/rwf-2000.zip\n",
            "replace rwf-2000/train/NonFight/RFAA8QO7_0/frame025.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
        "        \"\"\"\n",
        "        Initialize ConvLSTM cell.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size: (int, int)\n",
        "            Height and width of input tensor as (height, width).\n",
        "        input_dim: int\n",
        "            Number of channels of input tensor.\n",
        "        hidden_dim: int\n",
        "            Number of channels of hidden state.\n",
        "        kernel_size: (int, int)\n",
        "            Size of the convolutional kernel.\n",
        "        bias: bool\n",
        "            Whether or not to add the bias.\n",
        "        \"\"\"\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.height, self.width = input_size\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "        self.bias = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        # concatenate along channel axis\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
        "\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(\n",
        "            combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_hidden(self, batch_size, tensor_size):\n",
        "        height, width = tensor_size\n",
        "        return (Variable(torch.zeros(batch_size, self.hidden_dim, height, width)).cuda(),\n",
        "                Variable(torch.zeros(batch_size, self.hidden_dim, height, width)).cuda())\n",
        "\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
        "                 batch_first=False, bias=True, return_all_layers=False):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self._check_kernel_size_consistency(kernel_size)\n",
        "\n",
        "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
        "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
        "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
        "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
        "            raise ValueError('Inconsistent list length.')\n",
        "\n",
        "        self.height, self.width = input_size\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
        "\n",
        "            cell_list.append(ConvLSTMCell(input_size=(self.height, self.width),\n",
        "                                          input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "    def forward(self, input_tensor, hidden_state=None):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor: todo\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state: todo\n",
        "            None. todo implement stateful\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        \"\"\"\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        # Implement stateful ConvLSTM\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            tensor_size = (input_tensor.size(3), input_tensor.size(4))\n",
        "            hidden_state = self._init_hidden(\n",
        "                batch_size=input_tensor.size(0), tensor_size=tensor_size)\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = input_tensor\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "\n",
        "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
        "                                                 cur_state=[h, c])\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size, tensor_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(\n",
        "                self.cell_list[i].init_hidden(batch_size, tensor_size))\n",
        "        return init_states\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_kernel_size_consistency(kernel_size):\n",
        "        if not (isinstance(kernel_size, tuple) or\n",
        "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
        "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
        "\n",
        "    @staticmethod\n",
        "    def _extend_for_multilayer(param, num_layers):\n",
        "        if not isinstance(param, list):\n",
        "            param = [param] * num_layers\n",
        "        return param\n",
        "\n",
        "\n",
        "class ConvBLSTM(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(self, input_size, input_dim, hidden_dim,\n",
        "                 kernel_size, num_layers, batch_first=False, bias=True, return_all_layers=False):\n",
        "\n",
        "        super(ConvBLSTM, self).__init__()\n",
        "        self.forward_net = ConvLSTM(input_size, input_dim, hidden_dims//2, kernel_size,\n",
        "                                    num_layers, batch_first=batch_first, bias=bias,\n",
        "                                    return_all_layers=return_all_layers)\n",
        "        self.reverse_net = ConvLSTM(input_size, input_dim, hidden_dims//2, kernel_size,\n",
        "                                    num_layers, batch_first=batch_first, bias=bias,\n",
        "                                    return_all_layers=return_all_layers)\n",
        "\n",
        "    def forward(self, xforward, xreverse):\n",
        "        \"\"\"\n",
        "        xforward, xreverse = B T C H W tensors.\n",
        "        \"\"\"\n",
        "\n",
        "        y_out_fwd, _ = self.forward_net(xforward)\n",
        "        y_out_rev, _ = self.reverse_net(xreverse)\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            # outputs of last CLSTM layer = B, T, C, H, W\n",
        "            y_out_fwd = y_out_fwd[-1]\n",
        "            # outputs of last CLSTM layer = B, T, C, H, W\n",
        "            y_out_rev = y_out_rev[-1]\n",
        "\n",
        "        reversed_idx = list(reversed(range(y_out_rev.shape[1])))\n",
        "        # reverse temporal outputs.\n",
        "        y_out_rev = y_out_rev[:, reversed_idx, ...]\n",
        "        ycat = torch.cat((y_out_fwd, y_out_rev), dim=2)\n",
        "\n",
        "        return ycat\n"
      ],
      "metadata": {
        "id": "FOHpXJwfHAF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeformableConvLSTM(ConvLSTM):\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers, front_RBs, groups,\n",
        "                 batch_first=False, bias=True, return_all_layers=False):\n",
        "        ConvLSTM.__init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
        "                          batch_first=batch_first, bias=bias, return_all_layers=return_all_layers)\n",
        "        # extract features (for each frame)\n",
        "        nf = input_dim\n",
        "\n",
        "        self.pcd_h = Easy_PCD(nf=nf, groups=groups)\n",
        "        self.pcd_c = Easy_PCD(nf=nf, groups=groups)\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
        "            cell_list.append(ConvLSTMCell(input_size=(self.height, self.width),\n",
        "                                          input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "        # activation function\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
        "\n",
        "    def forward(self, input_tensor, hidden_state=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor:\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state:\n",
        "            None.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        '''\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            tensor_size = (input_tensor.size(3), input_tensor.size(4))\n",
        "            hidden_state = self._init_hidden(\n",
        "                batch_size=input_tensor.size(0), tensor_size=tensor_size)\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = input_tensor\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "                in_tensor = cur_layer_input[:, t, :, :, :]\n",
        "                h_temp = self.pcd_h(in_tensor, h)\n",
        "                c_temp = self.pcd_c(in_tensor, c)\n",
        "                h, c = self.cell_list[layer_idx](input_tensor=in_tensor,\n",
        "                                                 cur_state=[h_temp, c_temp])\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size, tensor_size):\n",
        "        return super()._init_hidden(batch_size, tensor_size)\n",
        "\n",
        "\n",
        "class BiDeformableConvLSTM(nn.Module):\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers, front_RBs, groups,\n",
        "                 batch_first=False, bias=True, return_all_layers=False):\n",
        "        super(BiDeformableConvLSTM, self).__init__()\n",
        "        self.forward_net = DeformableConvLSTM(input_size=input_size, input_dim=input_dim, hidden_dim=hidden_dim,\n",
        "                                              kernel_size=kernel_size, num_layers=num_layers, front_RBs=front_RBs,\n",
        "                                              groups=groups, batch_first=batch_first, bias=bias, return_all_layers=return_all_layers)\n",
        "        self.conv_1x1 = nn.Conv2d(2*input_dim, input_dim, 1, 1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        reversed_idx = list(reversed(range(x.shape[1])))\n",
        "        x_rev = x[:, reversed_idx, ...]\n",
        "        out_fwd, _ = self.forward_net(x)\n",
        "        out_rev, _ = self.forward_net(x_rev)\n",
        "        rev_rev = out_rev[0][:, reversed_idx, ...]\n",
        "        B, N, C, H, W = out_fwd[0].size()\n",
        "        result = torch.cat((out_fwd[0], rev_rev), dim=2)\n",
        "        result = result.view(B*N, -1, H, W)\n",
        "        result = self.conv_1x1(result)\n",
        "        return result.view(B, -1, C, H, W)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import functools\n",
        "\n",
        "\n",
        "def initialize_weights(net_l, scale=1):\n",
        "    if not isinstance(net_l, list):\n",
        "        net_l = [net_l]\n",
        "    for net in net_l:\n",
        "        for m in net.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
        "                m.weight.data *= scale  # for residual block\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
        "                m.weight.data *= scale\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def make_layer(block, n_layers):\n",
        "    layers = []\n",
        "    for _ in range(n_layers):\n",
        "        layers.append(block())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class ResidualBlock_noBN(nn.Module):\n",
        "    '''Residual block w/o BN\n",
        "    ---Conv-ReLU-Conv-+-\n",
        "     |________________|\n",
        "    '''\n",
        "\n",
        "    def __init__(self, nf=64):\n",
        "        super(ResidualBlock_noBN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.conv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "\n",
        "        # initialization\n",
        "        initialize_weights([self.conv1, self.conv2], 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = F.relu(self.conv1(x), inplace=True)\n",
        "        out = self.conv2(out)\n",
        "        return identity + out\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, input_size, nf=64, nframes=3, front_RBs=5, back_RBs=10):\n",
        "    super(Model, self).__init__()\n",
        "    self.nf=64\n",
        "    self.nframes=3\n",
        "    self.img_size = input_size\n",
        "    self.resnet = resnet18(pretrained=True)\n",
        "    self.resnet.fc = nn.Sequential(nn.Linear(self.resnet.fc.in_features, 512))\n",
        "    # self.resnet_feature = torch.nn.Sequential(*(list(self.resnet.children())[:-2]))\n",
        "    from mamba_ssm import Mamba\n",
        "    n_blocks = 1\n",
        "    self.mamba_layers = nn.ModuleList([Mamba(d_model = self.img_size*4 , d_state = 256, d_conv = 4, expand=8) for _ in range(n_blocks)])\n",
        "    # self.fc1 = nn.Linear(512, 256)\n",
        "    # self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    # upsampling\n",
        "    self.upconv1 = nn.Conv2d(nf, nf * 4, 3, 1, 1, bias=True)\n",
        "    self.upconv2 = nn.Conv2d(nf, 64 * 4, 3, 1, 1, bias=True)\n",
        "    self.pixel_shuffle = nn.PixelShuffle(2)\n",
        "    self.HRconv = nn.Conv2d(64, 64, 3, 1, 1, bias=True)\n",
        "    self.conv_last = nn.Conv2d(64, 3, 3, 1, 1, bias=True)\n",
        "\n",
        "    # activation function\n",
        "    self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
        "    # reconstruction\n",
        "    ResidualBlock_noBN_f = functools.partial(\n",
        "            ResidualBlock_noBN, nf=nf)\n",
        "    self.recon_trunk = make_layer(ResidualBlock_noBN_f, back_RBs)\n",
        "  def forward(self, x_3d):\n",
        "    x_3d = x_3d.permute(0, 2, 1, 3, 4)\n",
        "    features = []\n",
        "    for t in range(x_3d.size(1)):\n",
        "      x = self.resnet(x_3d[:, t, :, :, :])\n",
        "      features.append(x)\n",
        "    x = torch.stack(features, dim = 1)\n",
        "    for mamba in self.mamba_layers:\n",
        "      x = mamba(x)\n",
        "    # print(f'X shape: {x.shape()}')\n",
        "    # B, _, _ = x.size()\n",
        "\n",
        "    # x = x.view(B, -1, -1)\n",
        "\n",
        "    # out = self.recon_trunk(x)\n",
        "    # out = self.lrelu(self.pixel_shuffle(self.upconv1(out)))\n",
        "    # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))\n",
        "\n",
        "    # out = self.lrelu(self.HRconv(out))\n",
        "    # out = self.conv_last(out)\n",
        "    # _, _, K, G = out.size()\n",
        "    # outs = out.view(B, self.nframes, -1, K, G)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Dv4Llljl3m5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(224*224).cuda()\n",
        "# Check param\n",
        "param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Model has {param} parameters\")\n",
        "\n",
        "# Test the model with a random input (batch_size, channels, frames, height, width)\n",
        "inputs = torch.rand(1, 3, 2, 224, 224).cuda()\n",
        "\n",
        "output = model(inputs)\n",
        "\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "ZL7JiZY0Zlrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}